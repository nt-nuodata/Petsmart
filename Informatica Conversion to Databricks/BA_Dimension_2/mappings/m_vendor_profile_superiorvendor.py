# Databricks notebook source
# MAGIC %run "./udf_informatica"

# COMMAND ----------


from pyspark.sql.types import *

spark.sql("use DELTA_TRAINING")
spark.sql("set spark.sql.legacy.timeParserPolicy = LEGACY")


# COMMAND ----------

# DBTITLE 1, VENDOR_PROFILE_0

df_0=spark.sql("""
    SELECT
        VENDOR_ID AS VENDOR_ID,
        VENDOR_NAME AS VENDOR_NAME,
        VENDOR_TYPE_ID AS VENDOR_TYPE_ID,
        VENDOR_NBR AS VENDOR_NBR,
        LOCATION_ID AS LOCATION_ID,
        SUPERIOR_VENDOR_ID AS SUPERIOR_VENDOR_ID,
        PARENT_VENDOR_ID AS PARENT_VENDOR_ID,
        PARENT_VENDOR_NAME AS PARENT_VENDOR_NAME,
        PURCH_GROUP_ID AS PURCH_GROUP_ID,
        EDI_ELIG_FLAG AS EDI_ELIG_FLAG,
        PURCHASE_BLOCK AS PURCHASE_BLOCK,
        POSTING_BLOCK AS POSTING_BLOCK,
        DELETION_FLAG AS DELETION_FLAG,
        VIP_CD AS VIP_CD,
        INACTIVE_FLAG AS INACTIVE_FLAG,
        PAYMENT_TERM_CD AS PAYMENT_TERM_CD,
        INCO_TERM_CD AS INCO_TERM_CD,
        ADDRESS AS ADDRESS,
        CITY AS CITY,
        STATE AS STATE,
        COUNTRY_CD AS COUNTRY_CD,
        ZIP AS ZIP,
        CONTACT AS CONTACT,
        CONTACT_PHONE AS CONTACT_PHONE,
        PHONE AS PHONE,
        PHONE_EXT AS PHONE_EXT,
        FAX AS FAX,
        RTV_ELIG_FLAG AS RTV_ELIG_FLAG,
        RTV_TYPE_CD AS RTV_TYPE_CD,
        RTV_FREIGHT_TYPE_CD AS RTV_FREIGHT_TYPE_CD,
        INDUSTRY_CD AS INDUSTRY_CD,
        LATITUDE AS LATITUDE,
        LONGITUDE AS LONGITUDE,
        TIME_ZONE_ID AS TIME_ZONE_ID,
        ADD_DT AS ADD_DT,
        UPDATE_DT AS UPDATE_DT,
        LOAD_DT AS LOAD_DT,
        monotonically_increasing_id() AS Monotonically_Increasing_Id 
    FROM
        VENDOR_PROFILE""")

df_0.createOrReplaceTempView("VENDOR_PROFILE_0")

# COMMAND ----------

# DBTITLE 1, SQ_Shortcut_to_VENDOR_PROFILE_1

df_1=spark.sql("""
    SELECT
        VENDOR_ID AS VENDOR_ID,
        VENDOR_NAME AS VENDOR_NAME,
        VENDOR_TYPE_ID AS VENDOR_TYPE_ID,
        VENDOR_NBR AS VENDOR_NBR,
        LOCATION_ID AS LOCATION_ID,
        SUPERIOR_VENDOR_ID AS SUPERIOR_VENDOR_ID,
        PARENT_VENDOR_ID AS PARENT_VENDOR_ID,
        PARENT_VENDOR_NAME AS PARENT_VENDOR_NAME,
        PURCH_GROUP_ID AS PURCH_GROUP_ID,
        EDI_ELIG_FLAG AS EDI_ELIG_FLAG,
        PURCHASE_BLOCK AS PURCHASE_BLOCK,
        POSTING_BLOCK AS POSTING_BLOCK,
        DELETION_FLAG AS DELETION_FLAG,
        VIP_CD AS VIP_CD,
        INACTIVE_FLAG AS INACTIVE_FLAG,
        PAYMENT_TERM_CD AS PAYMENT_TERM_CD,
        INCO_TERM_CD AS INCO_TERM_CD,
        ADDRESS AS ADDRESS,
        CITY AS CITY,
        STATE AS STATE,
        COUNTRY_CD AS COUNTRY_CD,
        ZIP AS ZIP,
        CONTACT AS CONTACT,
        CONTACT_PHONE AS CONTACT_PHONE,
        PHONE AS PHONE,
        PHONE_EXT AS PHONE_EXT,
        FAX AS FAX,
        RTV_ELIG_FLAG AS RTV_ELIG_FLAG,
        RTV_TYPE_CD AS RTV_TYPE_CD,
        RTV_FREIGHT_TYPE_CD AS RTV_FREIGHT_TYPE_CD,
        INDUSTRY_CD AS INDUSTRY_CD,
        LATITUDE AS LATITUDE,
        LONGITUDE AS LONGITUDE,
        TIME_ZONE_ID AS TIME_ZONE_ID,
        ADD_DT AS ADD_DT,
        UPDATE_DT AS UPDATE_DT,
        LOAD_DT AS LOAD_DT,
        Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        VENDOR_PROFILE_0""")

df_1.createOrReplaceTempView("SQ_Shortcut_to_VENDOR_PROFILE_1")

# COMMAND ----------

# DBTITLE 1, LKP_VENDOR_PROFILE_PRE_2

df_2=spark.sql("""
    SELECT
        SUPERIOR_VENDOR_NBR AS SUPERIOR_VENDOR_NBR,
        SQ_Shortcut_to_VENDOR_PROFILE_1.VENDOR_TYPE_ID AS VENDOR_TYPE_ID1,
        SQ_Shortcut_to_VENDOR_PROFILE_1.VENDOR_NBR AS VENDOR_NBR1,
        SQ_Shortcut_to_VENDOR_PROFILE_1.Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        VENDOR_PROFILE_PRE 
    RIGHT OUTER JOIN
        SQ_Shortcut_to_VENDOR_PROFILE_1 
            ON VENDOR_PROFILE_PRE.VENDOR_TYPE_ID = SQ_Shortcut_to_VENDOR_PROFILE_1.VENDOR_TYPE_ID 
            AND VENDOR_PROFILE_PRE.VENDOR_NBR = VENDOR_NBR1""")

df_2.createOrReplaceTempView("LKP_VENDOR_PROFILE_PRE_2")

# COMMAND ----------

# DBTITLE 1, EXP_3

df_3=spark.sql("""
    SELECT
        SQ_Shortcut_to_VENDOR_PROFILE_1.VENDOR_ID AS VENDOR_ID,
        SQ_Shortcut_to_VENDOR_PROFILE_1.VENDOR_TYPE_ID AS VENDOR_TYPE_ID,
        LKP_VENDOR_PROFILE_PRE_2.SUPERIOR_VENDOR_NBR AS SUPERIOR_VENDOR_NBR,
        SQ_Shortcut_to_VENDOR_PROFILE_1.Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        SQ_Shortcut_to_VENDOR_PROFILE_1 
    INNER JOIN
        LKP_VENDOR_PROFILE_PRE_2 
            ON SQ_Shortcut_to_VENDOR_PROFILE_1.Monotonically_Increasing_Id = LKP_VENDOR_PROFILE_PRE_2.Monotonically_Increasing_Id""")

df_3.createOrReplaceTempView("EXP_3")

# COMMAND ----------

# DBTITLE 1, LKP_DM_PG_VENDOR_4

df_4=spark.sql("""
    SELECT
        VENDOR_ID AS VENDOR_ID,
        PURCH_GROUP_ID AS PURCH_GROUP_ID,
        EXP_3.VENDOR_ID AS VENDOR_ID1,
        EXP_3.Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        DM_PG_VENDOR 
    RIGHT OUTER JOIN
        EXP_3 
            ON VENDOR_ID = EXP_3.VENDOR_ID""")

df_4.createOrReplaceTempView("LKP_DM_PG_VENDOR_4")

# COMMAND ----------

# DBTITLE 1, LKP_VENDOR_PROFILE1_5

df_5=spark.sql("""
    SELECT
        VENDOR_ID AS VENDOR_ID,
        VENDOR_NAME AS VENDOR_NAME,
        EXP_3.Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        VENDOR_PROFILE 
    RIGHT OUTER JOIN
        EXP_3 
            ON VENDOR_PROFILE.VENDOR_TYPE_ID = EXP_3.VENDOR_TYPE_ID 
            AND VENDOR_PROFILE.VENDOR_NBR = SUPERIOR_VENDOR_NBR""")

df_5.createOrReplaceTempView("LKP_VENDOR_PROFILE1_5")

# COMMAND ----------

# DBTITLE 1, UPD_Update_6

df_6=spark.sql("""
    SELECT
        VENDOR_ID AS VENDOR_ID,
        SUPERIOR_VENDOR_NBR AS SUPERIOR_VENDOR_ID,
        VENDOR_NAME AS VENDOR_NAME,
        PURCH_GROUP_ID AS PURCH_GROUP_ID,
        Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        EXP_3""")

df_6.createOrReplaceTempView("UPD_Update_6")

df_6=spark.sql("""
    SELECT
        VENDOR_ID AS VENDOR_ID,
        SUPERIOR_VENDOR_NBR AS SUPERIOR_VENDOR_ID,
        VENDOR_NAME AS VENDOR_NAME,
        PURCH_GROUP_ID AS PURCH_GROUP_ID,
        Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        LKP_DM_PG_VENDOR_4""")

df_6.createOrReplaceTempView("UPD_Update_6")

df_6=spark.sql("""
    SELECT
        VENDOR_ID AS VENDOR_ID,
        SUPERIOR_VENDOR_NBR AS SUPERIOR_VENDOR_ID,
        VENDOR_NAME AS VENDOR_NAME,
        PURCH_GROUP_ID AS PURCH_GROUP_ID,
        Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        LKP_VENDOR_PROFILE1_5""")

df_6.createOrReplaceTempView("UPD_Update_6")

# COMMAND ----------

# DBTITLE 1, VENDOR_PROFILE

spark.sql("""INSERT INTO VENDOR_PROFILE SELECT NEXTVAL AS VENDOR_ID,
VENDOR_NAME AS VENDOR_NAME,
VENDOR_TYPE_ID AS VENDOR_TYPE_ID,
VENDOR_NBR AS VENDOR_NBR,
LOCATION_ID AS LOCATION_ID,
SUPERIOR_VENDOR_ID AS SUPERIOR_VENDOR_ID,
PARENT_VENDOR_ID AS PARENT_VENDOR_ID,
PARENT_VENDOR_NAME AS PARENT_VENDOR_NAME,
PURCH_GROUP_ID AS PURCH_GROUP_ID,
EDI_ELIG_FLAG AS EDI_ELIG_FLAG,
PURCHASE_BLOCK AS PURCHASE_BLOCK,
POSTING_BLOCK AS POSTING_BLOCK,
DELETION_FLAG AS DELETION_FLAG,
VIP_CD AS VIP_CD,
INACTIVE_FLAG AS INACTIVE_FLAG,
PAYMENT_TERM_CD AS PAYMENT_TERM_CD,
INCO_TERM_CD AS INCO_TERM_CD,
ADDRESS AS ADDRESS,
CITY AS CITY,
STATE AS STATE,
COUNTRY_CD AS COUNTRY_CD,
ZIP AS ZIP,
CONTACT AS CONTACT,
CONTACT_PHONE AS CONTACT_PHONE,
PHONE AS PHONE,
PHONE_EXT AS PHONE_EXT,
FAX AS FAX,
RTV_ELIG_FLAG AS RTV_ELIG_FLAG,
RTV_TYPE_CD AS RTV_TYPE_CD,
RTV_FREIGHT_TYPE_CD AS RTV_FREIGHT_TYPE_CD,
INDUSTRY_CD AS INDUSTRY_CD,
LATITUDE AS LATITUDE,
LONGITUDE AS LONGITUDE,
TIME_ZONE_ID AS TIME_ZONE_ID,
ADD_DT AS ADD_DT,
UPDATE_DT AS UPDATE_DT,
LOAD_DT AS LOAD_DT FROM UPD_Update_6""")
