# Databricks notebook source
# MAGIC %run "./udf_informatica"

# COMMAND ----------


from pyspark.sql.types import *

spark.sql("use DELTA_TRAINING")
spark.sql("set spark.sql.legacy.timeParserPolicy = LEGACY")


# COMMAND ----------
# DBTITLE 1, MA_GL_ACCT_CTRL_0


df_0=spark.sql("""
    SELECT
        MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
        GL_ACCT_NBR AS GL_ACCT_NBR,
        START_EFF_DT AS START_EFF_DT,
        END_EFF_DT AS END_EFF_DT,
        DC_COST_OVERRIDE_IND AS DC_COST_OVERRIDE_IND,
        UPDATE_TSTMP AS UPDATE_TSTMP,
        LOAD_TSTMP AS LOAD_TSTMP,
        monotonically_increasing_id() AS Monotonically_Increasing_Id 
    FROM
        MA_GL_ACCT_CTRL""")

df_0.createOrReplaceTempView("MA_GL_ACCT_CTRL_0")

# COMMAND ----------
# DBTITLE 1, MA_OB_FREIGHT_CTRL_1


df_1=spark.sql("""
    SELECT
        FROM_LOCATION_ID AS FROM_LOCATION_ID,
        FISCAL_MO AS FISCAL_MO,
        R12_NET_SALES_COST AS R12_NET_SALES_COST,
        R12_OB_FREIGHT_COST AS R12_OB_FREIGHT_COST,
        R12_OB_FREIGHT_PCT AS R12_OB_FREIGHT_PCT,
        ACT_NET_SALES_COST AS ACT_NET_SALES_COST,
        ACT_OB_FREIGHT_COST AS ACT_OB_FREIGHT_COST,
        ACT_OB_FREIGHT_PCT AS ACT_OB_FREIGHT_PCT,
        UPDATE_TSTMP AS UPDATE_TSTMP,
        LOAD_TSTMP AS LOAD_TSTMP,
        monotonically_increasing_id() AS Monotonically_Increasing_Id 
    FROM
        MA_OB_FREIGHT_CTRL""")

df_1.createOrReplaceTempView("MA_OB_FREIGHT_CTRL_1")

# COMMAND ----------
# DBTITLE 1, MA_FISCAL_MO_CTRL_2


df_2=spark.sql("""
    SELECT
        FISCAL_MO AS FISCAL_MO,
        RESTATE_DT AS RESTATE_DT,
        UPDATE_TSTMP AS UPDATE_TSTMP,
        LOAD_TSTMP AS LOAD_TSTMP,
        monotonically_increasing_id() AS Monotonically_Increasing_Id 
    FROM
        MA_FISCAL_MO_CTRL""")

df_2.createOrReplaceTempView("MA_FISCAL_MO_CTRL_2")

# COMMAND ----------
# DBTITLE 1, MA_EVENT_3


df_3=spark.sql("""
    SELECT
        MA_EVENT_ID AS MA_EVENT_ID,
        OFFER_ID AS OFFER_ID,
        SAP_DEPT_ID AS SAP_DEPT_ID,
        PRODUCT_ID AS PRODUCT_ID,
        COUNTRY_CD AS COUNTRY_CD,
        START_DT AS START_DT,
        END_DT AS END_DT,
        MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
        MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
        LOCATION_ID AS LOCATION_ID,
        MOVEMENT_ID AS MOVEMENT_ID,
        VALUATION_CLASS_CD AS VALUATION_CLASS_CD,
        GL_ACCT_NBR AS GL_ACCT_NBR,
        LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
        ROYALTY_BRAND_ID AS ROYALTY_BRAND_ID,
        BRAND_CD AS BRAND_CD,
        MA_FORMULA_CD AS MA_FORMULA_CD,
        FISCAL_MO AS FISCAL_MO,
        SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
        FROM_LOCATION_ID AS FROM_LOCATION_ID,
        SOURCE_VENDOR_ID AS SOURCE_VENDOR_ID,
        COMPANY_ID AS COMPANY_ID,
        MA_EVENT_DESC AS MA_EVENT_DESC,
        EM_VENDOR_FUNDING_ID AS EM_VENDOR_FUNDING_ID,
        EM_COMMENT AS EM_COMMENT,
        EM_BILL_ALT_VENDOR_FLAG AS EM_BILL_ALT_VENDOR_FLAG,
        EM_ALT_VENDOR_ID AS EM_ALT_VENDOR_ID,
        EM_ALT_VENDOR_NAME AS EM_ALT_VENDOR_NAME,
        EM_ALT_VENDOR_COUNTRY_CD AS EM_ALT_VENDOR_COUNTRY_CD,
        EM_VENDOR_ID AS EM_VENDOR_ID,
        EM_VENDOR_NAME AS EM_VENDOR_NAME,
        EM_VENDOR_COUNTRY_CD AS EM_VENDOR_COUNTRY_CD,
        VENDOR_NAME_TXT AS VENDOR_NAME_TXT,
        MA_PCT_IND AS MA_PCT_IND,
        MA_AMT AS MA_AMT,
        MA_MAX_AMT AS MA_MAX_AMT,
        UPDATE_DT AS UPDATE_DT,
        LOAD_DT AS LOAD_DT,
        monotonically_increasing_id() AS Monotonically_Increasing_Id 
    FROM
        MA_EVENT""")

df_3.createOrReplaceTempView("MA_EVENT_3")

# COMMAND ----------
# DBTITLE 1, SUPPLY_CHAIN_4


df_4=spark.sql("""
    SELECT
        PRODUCT_ID AS PRODUCT_ID,
        LOCATION_ID AS LOCATION_ID,
        DIRECT_VENDOR_ID AS DIRECT_VENDOR_ID,
        SOURCE_VENDOR_ID AS SOURCE_VENDOR_ID,
        PRIMARY_VENDOR_ID AS PRIMARY_VENDOR_ID,
        FROM_LOCATION_ID AS FROM_LOCATION_ID,
        monotonically_increasing_id() AS Monotonically_Increasing_Id 
    FROM
        SUPPLY_CHAIN""")

df_4.createOrReplaceTempView("SUPPLY_CHAIN_4")

# COMMAND ----------
# DBTITLE 1, MA_SALES_TRANS_UPC_5


df_5=spark.sql("""
    SELECT
        DAY_DT AS DAY_DT,
        LOCATION_ID AS LOCATION_ID,
        SALES_INSTANCE_ID AS SALES_INSTANCE_ID,
        UPC_ID AS UPC_ID,
        TP_INVOICE_NBR AS TP_INVOICE_NBR,
        PARENT_UPC_ID AS PARENT_UPC_ID,
        COMBO_TYPE_CD AS COMBO_TYPE_CD,
        POS_TXN_SEQ_NBR AS POS_TXN_SEQ_NBR,
        MA_EVENT_ID AS MA_EVENT_ID,
        PRODUCT_ID AS PRODUCT_ID,
        SALES_CUST_CAPTURE_CD AS SALES_CUST_CAPTURE_CD,
        MA_SALES_AMT AS MA_SALES_AMT,
        MA_SALES_QTY AS MA_SALES_QTY,
        EXCH_RATE_PCT AS EXCH_RATE_PCT,
        UPDATE_DT AS UPDATE_DT,
        LOAD_DT AS LOAD_DT,
        monotonically_increasing_id() AS Monotonically_Increasing_Id 
    FROM
        MA_SALES_TRANS_UPC""")

df_5.createOrReplaceTempView("MA_SALES_TRANS_UPC_5")

# COMMAND ----------
# DBTITLE 1, GL_ACCOUNT_PROFILE_6


df_6=spark.sql("""
    SELECT
        GL_ACCOUNT_GID AS GL_ACCOUNT_GID,
        GL_CHART_OF_ACCOUNTS_CD AS GL_CHART_OF_ACCOUNTS_CD,
        GL_ACCOUNT_NBR AS GL_ACCOUNT_NBR,
        GL_ACCOUNT_DESC AS GL_ACCOUNT_DESC,
        GL_ACCOUNT_GROUP_CD AS GL_ACCOUNT_GROUP_CD,
        GL_ACCOUNT_GROUP_DESC AS GL_ACCOUNT_GROUP_DESC,
        GL_BAL_SHEET_IND AS GL_BAL_SHEET_IND,
        GL_PL_IND AS GL_PL_IND,
        UPDATE_DT AS UPDATE_DT,
        LOAD_DT AS LOAD_DT,
        monotonically_increasing_id() AS Monotonically_Increasing_Id 
    FROM
        GL_ACCOUNT_PROFILE""")

df_6.createOrReplaceTempView("GL_ACCOUNT_PROFILE_6")

# COMMAND ----------
# DBTITLE 1, GL_PROFIT_CENTER_PROFILE_7


df_7=spark.sql("""
    SELECT
        GL_PROFIT_CENTER_GID AS GL_PROFIT_CENTER_GID,
        GL_COMPANY_CD AS GL_COMPANY_CD,
        GL_PROFIT_CENTER_CD AS GL_PROFIT_CENTER_CD,
        GL_PROFIT_CENTER_DESC AS GL_PROFIT_CENTER_DESC,
        GL_HIERARCHY_AREA AS GL_HIERARCHY_AREA,
        VALID_FROM_DT AS VALID_FROM_DT,
        VALID_TO_DT AS VALID_TO_DT,
        CURRENCY_ID AS CURRENCY_ID,
        LOCATION_ID AS LOCATION_ID,
        UPDATE_DT AS UPDATE_DT,
        LOAD_DT AS LOAD_DT,
        monotonically_increasing_id() AS Monotonically_Increasing_Id 
    FROM
        GL_PROFIT_CENTER_PROFILE""")

df_7.createOrReplaceTempView("GL_PROFIT_CENTER_PROFILE_7")

# COMMAND ----------
# DBTITLE 1, DAYS_8


df_8=spark.sql("""
    SELECT
        DAY_DT AS DAY_DT,
        BUSINESS_DAY_FLAG AS BUSINESS_DAY_FLAG,
        HOLIDAY_FLAG AS HOLIDAY_FLAG,
        DAY_OF_WK_NAME AS DAY_OF_WK_NAME,
        DAY_OF_WK_NAME_ABBR AS DAY_OF_WK_NAME_ABBR,
        DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
        CAL_DAY_OF_MO_NBR AS CAL_DAY_OF_MO_NBR,
        CAL_DAY_OF_YR_NBR AS CAL_DAY_OF_YR_NBR,
        CAL_WK AS CAL_WK,
        CAL_WK_NBR AS CAL_WK_NBR,
        CAL_MO AS CAL_MO,
        CAL_MO_NBR AS CAL_MO_NBR,
        CAL_MO_NAME AS CAL_MO_NAME,
        CAL_MO_NAME_ABBR AS CAL_MO_NAME_ABBR,
        CAL_QTR AS CAL_QTR,
        CAL_QTR_NBR AS CAL_QTR_NBR,
        CAL_HALF AS CAL_HALF,
        CAL_YR AS CAL_YR,
        FISCAL_DAY_OF_MO_NBR AS FISCAL_DAY_OF_MO_NBR,
        FISCAL_DAY_OF_YR_NBR AS FISCAL_DAY_OF_YR_NBR,
        FISCAL_WK AS FISCAL_WK,
        FISCAL_WK_NBR AS FISCAL_WK_NBR,
        FISCAL_MO AS FISCAL_MO,
        FISCAL_MO_NBR AS FISCAL_MO_NBR,
        FISCAL_MO_NAME AS FISCAL_MO_NAME,
        FISCAL_MO_NAME_ABBR AS FISCAL_MO_NAME_ABBR,
        FISCAL_QTR AS FISCAL_QTR,
        FISCAL_QTR_NBR AS FISCAL_QTR_NBR,
        FISCAL_HALF AS FISCAL_HALF,
        FISCAL_YR AS FISCAL_YR,
        LYR_WEEK_DT AS LYR_WEEK_DT,
        LWK_WEEK_DT AS LWK_WEEK_DT,
        WEEK_DT AS WEEK_DT,
        EST_TIME_CONV_AMT AS EST_TIME_CONV_AMT,
        EST_TIME_CONV_HRS AS EST_TIME_CONV_HRS,
        ES0_TIME_CONV_AMT AS ES0_TIME_CONV_AMT,
        ES0_TIME_CONV_HRS AS ES0_TIME_CONV_HRS,
        CST_TIME_CONV_AMT AS CST_TIME_CONV_AMT,
        CST_TIME_CONV_HRS AS CST_TIME_CONV_HRS,
        CS0_TIME_CONV_AMT AS CS0_TIME_CONV_AMT,
        CS0_TIME_CONV_HRS AS CS0_TIME_CONV_HRS,
        MST_TIME_CONV_AMT AS MST_TIME_CONV_AMT,
        MST_TIME_CONV_HRS AS MST_TIME_CONV_HRS,
        MS0_TIME_CONV_AMT AS MS0_TIME_CONV_AMT,
        MS0_TIME_CONV_HRS AS MS0_TIME_CONV_HRS,
        PST_TIME_CONV_AMT AS PST_TIME_CONV_AMT,
        PST_TIME_CONV_HRS AS PST_TIME_CONV_HRS,
        monotonically_increasing_id() AS Monotonically_Increasing_Id 
    FROM
        DAYS""")

df_8.createOrReplaceTempView("DAYS_8")

# COMMAND ----------
# DBTITLE 1, SQ_MA_OB_FREIGHT_CTRL_UPD_9


df_9=spark.sql("""
    SELECT
        SC.FROM_LOCATION_ID,
        SC.FISCAL_MO,
        SC.R12_NET_SALES_COST,
        SC.R12_OB_FREIGHT_COST,
        SC.R12_OB_FREIGHT_PCT,
        SC.ACT_NET_SALES_COST,
        NVL(GLA.ACT_OB_FREIGHT_COST,
        0) ACT_OB_FREIGHT_COST,
        CASE 
            WHEN SC.ACT_NET_SALES_COST = 0 THEN 0 
            ELSE NVL(GLA.ACT_OB_FREIGHT_COST,
            0) / SC.ACT_NET_SALES_COST 
        END ACT_OB_FREIGHT_PCT,
        SC.UPDATE_TSTMP 
    FROM
        (SELECT
            MOFC.FROM_LOCATION_ID,
            MOFC.FISCAL_MO,
            MAX(MOFC.R12_NET_SALES_COST) R12_NET_SALES_COST,
            MAX(MOFC.R12_OB_FREIGHT_COST) R12_OB_FREIGHT_COST,
            MAX(MOFC.R12_OB_FREIGHT_PCT) R12_OB_FREIGHT_PCT,
            ROUND(NVL(SUM((STU.SALES_COST - STU.RETURN_COST) * STU.EXCH_RATE_PCT),
            0),
            2) ACT_NET_SALES_COST,
            MAX(MOFC.UPDATE_TSTMP) UPDATE_TSTMP 
        FROM
            MA_OB_FREIGHT_CTRL MOFC 
        JOIN
            MA_EVENT ME 
                ON MOFC.FROM_LOCATION_ID = ME.FROM_LOCATION_ID 
                AND MOFC.FISCAL_MO = ME.FISCAL_MO 
                AND ME.MA_EVENT_TYPE_ID = 70 
        JOIN
            MA_SALES_TRANS_UPC MSTU 
                ON ME.MA_EVENT_ID = MSTU.MA_EVENT_ID 
        JOIN
            MA_FISCAL_MO_CTRL MFMC 
                ON MOFC.FISCAL_MO = MFMC.FISCAL_MO 
                AND MFMC.RESTATE_DT = CURRENT_DATE 
        JOIN
            SALES_TRANS_UPC STU 
                ON MSTU.DAY_DT = STU.DAY_DT 
                AND MSTU.LOCATION_ID = STU.LOCATION_ID 
                AND MSTU.SALES_INSTANCE_ID = STU.SALES_INSTANCE_ID 
                AND MSTU.UPC_ID = STU.UPC_ID 
                AND MSTU.TP_INVOICE_NBR = STU.TP_INVOICE_NBR 
                AND MSTU.PARENT_UPC_ID = STU.PARENT_UPC_ID 
                AND MSTU.COMBO_TYPE_CD = STU.COMBO_TYPE_CD 
                AND MSTU.POS_TXN_SEQ_NBR = STU.POS_TXN_SEQ_NBR 
        GROUP BY
            MOFC.FROM_LOCATION_ID,
            MOFC.FISCAL_MO) SC 
    LEFT JOIN
        (
            SELECT
                GAD.FISCAL_MO,
                CASE 
                    WHEN SITE.LOCATION_TYPE_ID IN (1,
                    3) THEN SITE.LOCATION_ID 
                    WHEN SUBSTR(GPCP.GL_PROFIT_CENTER_CD,
                    1,
                    8) = '00000039' THEN SITE2.LOCATION_ID 
                    ELSE 0 
                END FROM_LOCATION_ID,
                SUM(GAD.GL_GRP_AMT) ACT_OB_FREIGHT_COST 
            FROM
                GL_ACTUAL_DETAIL GAD 
            JOIN
                GL_ACCOUNT_PROFILE GAP 
                    ON GAD.GL_ACCOUNT_GID = GAP.GL_ACCOUNT_GID 
            JOIN
                GL_PROFIT_CENTER_PROFILE GPCP 
                    ON GAD.GL_PROFIT_CENTER_GID = GPCP.GL_PROFIT_CENTER_GID 
            JOIN
                DM_GL_COA DGC 
                    ON GAP.GL_ACCOUNT_NBR = DGC.GL_ACCT_NBR 
            JOIN
                SITE_PROFILE SITE 
                    ON GAD.LOCATION_ID = SITE.LOCATION_ID 
            JOIN
                MA_FISCAL_MO_CTRL MFMC 
                    ON GAD.FISCAL_MO = MFMC.FISCAL_MO 
                    AND MFMC.RESTATE_DT = CURRENT_DATE 
            JOIN
                (
                    SELECT
                        MA_EVENT_TYPE_VAR_VALUE,
                        START_EFF_DT,
                        END_EFF_DT 
                    FROM
                        MA_EVENT_TYPE_VAR_CTRL 
                    WHERE
                        MA_EVENT_TYPE_ID = 70 
                        AND MA_EVENT_TYPE_VAR_TYPE_CD = 'STORE_LNBR'
                ) DCSLE 
                    ON DGC.STORE_LNBR::VARCHAR (25) = DCSLE.MA_EVENT_TYPE_VAR_VALUE 
                    AND GAD.GL_POSTING_DT BETWEEN DCSLE.START_EFF_DT AND DCSLE.END_EFF_DT 
            LEFT JOIN
                (
                    SELECT
                        LPAD(STORE_NBR,
                        2,
                        '0') STORE_NBR,
                        LOCATION_ID 
                    FROM
                        SITE_PROFILE 
                    WHERE
                        LOCATION_TYPE_ID IN (
                            1, 3
                        ) 
                        AND LENGTH(STORE_NBR) <= 2
                ) SITE2 
                    ON CASE 
                        WHEN SUBSTR(GPCP.GL_PROFIT_CENTER_CD,
                    1,
                    8) = '00000039' THEN SUBSTR(GPCP.GL_PROFIT_CENTER_CD,
                    9,
                    2) 
                END = SITE2.STORE_NBR 
            GROUP BY
                GAD.FISCAL_MO,
                CASE 
                    WHEN SITE.LOCATION_TYPE_ID IN (1,
                    3) THEN SITE.LOCATION_ID 
                    WHEN SUBSTR(GPCP.GL_PROFIT_CENTER_CD,
                    1,
                    8) = '00000039' THEN SITE2.LOCATION_ID 
                    ELSE 0 
                END) GLA 
                    ON SC.FROM_LOCATION_ID = GLA.FROM_LOCATION_ID 
                    AND SC.FISCAL_MO = GLA.FISCAL_MO""")

df_9.createOrReplaceTempView("SQ_MA_OB_FREIGHT_CTRL_UPD_9")

# COMMAND ----------
# DBTITLE 1, EXP_UPDATE_10


df_10=spark.sql("""
    SELECT
        FROM_LOCATION_ID AS FROM_LOCATION_ID,
        FISCAL_MO AS FISCAL_MO,
        R12_NET_SALES_COST AS R12_NET_SALES_COST,
        R12_OB_FREIGHT_COST AS R12_OB_FREIGHT_COST,
        R12_OB_FREIGHT_PCT AS R12_OB_FREIGHT_PCT,
        ACT_NET_SALES_COST AS ACT_NET_SALES_COST,
        ACT_OB_FREIGHT_COST AS ACT_OB_FREIGHT_COST,
        ACT_OB_FREIGHT_PCT AS ACT_OB_FREIGHT_PCT,
        UPDATE_TSTMP AS UPDATE_TSTMP,
        current_timestamp AS LOAD_TSTMP,
        'U' AS INS_UPD_FLAG,
        Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        SQ_MA_OB_FREIGHT_CTRL_UPD_9""")

df_10.createOrReplaceTempView("EXP_UPDATE_10")

# COMMAND ----------
# DBTITLE 1, SQ_MA_OB_FREIGHT_CTRL_INS_11


df_11=spark.sql("""
    SELECT
        A.FROM_LOCATION_ID,
        A.FISCAL_MO,
        NVL(LR.EST_NET_SALES_COST,
        WR.EST_NET_SALES_COST) R12_NET_SALES_COST,
        NVL(LR.EST_OB_FREIGHT_COST,
        WR.EST_OB_FREIGHT_COST) R12_OB_FREIGHT_COST,
        NVL(LR.EST_OB_FREIGHT_PCT,
        WR.EST_OB_FREIGHT_PCT) R12_OB_FREIGHT_PCT 
    FROM
        (SELECT
            DISTINCT SC.FROM_LOCATION_ID,
            D.FISCAL_MO 
        FROM
            SUPPLY_CHAIN SC 
        JOIN
            SITE_PROFILE SITE 
                ON SC.FROM_LOCATION_ID = SITE.LOCATION_ID CROSS 
        JOIN
            (
                SELECT
                    DISTINCT FISCAL_MO 
                FROM
                    DAYS D 
                WHERE
                    DAY_DT = CURRENT_DATE - 1 
                    AND FISCAL_MO > (
                        SELECT
                            MAX(FISCAL_MO) 
                        FROM
                            MA_OB_FREIGHT_CTRL 
                        WHERE
                            ACT_NET_SALES_COST IS NOT NULL
                    )
                ) D 
            WHERE
                SITE.LOCATION_TYPE_ID IN (
                    1, 3
                )
        ) A 
    LEFT JOIN
        MA_OB_FREIGHT_CTRL MOFC 
            ON A.FROM_LOCATION_ID = MOFC.FROM_LOCATION_ID 
            AND A.FISCAL_MO = MOFC.FISCAL_MO 
    LEFT JOIN
        (
            SELECT
                FROM_LOCATION_ID,
                SUM(ACT_NET_SALES_COST) EST_NET_SALES_COST,
                SUM(ACT_OB_FREIGHT_COST) EST_OB_FREIGHT_COST,
                CASE 
                    WHEN EST_NET_SALES_COST <> 0 THEN EST_OB_FREIGHT_COST / EST_NET_SALES_COST 
                    ELSE 0 
                END EST_OB_FREIGHT_PCT,
                SUM(1) FISCAL_MO_CNT 
            FROM
                MA_OB_FREIGHT_CTRL 
            WHERE
                FISCAL_MO BETWEEN (SELECT
                    MAX(FISCAL_MO) - 99 
                FROM
                    MA_OB_FREIGHT_CTRL 
                WHERE
                    ACT_NET_SALES_COST IS NOT NULL) AND (
                    SELECT
                        MAX(FISCAL_MO) 
                    FROM
                        MA_OB_FREIGHT_CTRL 
                    WHERE
                        ACT_NET_SALES_COST IS NOT NULL
                ) 
            GROUP BY
                FROM_LOCATION_ID 
            HAVING
                FISCAL_MO_CNT >= 3
            ) LR 
                ON A.FROM_LOCATION_ID = LR.FROM_LOCATION_ID CROSS 
        JOIN
            (
                SELECT
                    SUM(ACT_NET_SALES_COST) EST_NET_SALES_COST,
                    SUM(ACT_OB_FREIGHT_COST) EST_OB_FREIGHT_COST,
                    CASE 
                        WHEN EST_NET_SALES_COST <> 0 THEN EST_OB_FREIGHT_COST / EST_NET_SALES_COST 
                        ELSE 0 
                    END EST_OB_FREIGHT_PCT 
                FROM
                    MA_OB_FREIGHT_CTRL 
                WHERE
                    FISCAL_MO BETWEEN (SELECT
                        MAX(FISCAL_MO) - 99 
                    FROM
                        MA_OB_FREIGHT_CTRL 
                    WHERE
                        ACT_NET_SALES_COST IS NOT NULL) AND (
                        SELECT
                            MAX(FISCAL_MO) 
                        FROM
                            MA_OB_FREIGHT_CTRL 
                        WHERE
                            ACT_NET_SALES_COST IS NOT NULL
                    )
                ) WR 
            WHERE
                MOFC.FROM_LOCATION_ID IS NULL""")

df_11.createOrReplaceTempView("SQ_MA_OB_FREIGHT_CTRL_INS_11")

# COMMAND ----------
# DBTITLE 1, EXP_INSERT_12


df_12=spark.sql("""
    SELECT
        FROM_LOCATION_ID AS FROM_LOCATION_ID,
        FISCAL_MO AS FISCAL_MO,
        R12_NET_SALES_COST AS R12_NET_SALES_COST,
        R12_OB_FREIGHT_COST AS R12_OB_FREIGHT_COST,
        R12_OB_FREIGHT_PCT AS R12_OB_FREIGHT_PCT,
        NULL AS ACT_NET_SALES_COST,
        NULL AS ACT_OB_FREIGHT_COST,
        NULL AS ACT_OB_FREIGHT_PCT,
        current_timestamp AS UPDATE_TSTMP,
        current_timestamp AS LOAD_TSTMP,
        'I' AS INS_UPD_FLAG,
        Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        SQ_MA_OB_FREIGHT_CTRL_INS_11""")

df_12.createOrReplaceTempView("EXP_INSERT_12")

# COMMAND ----------
# DBTITLE 1, UNI_OB_FREIGHT_13


df_13=spark.sql("""SELECT ACT_NET_SALES_COST AS ACT_NET_SALES_COST,
ACT_OB_FREIGHT_COST AS ACT_OB_FREIGHT_COST,
ACT_OB_FREIGHT_PCT AS ACT_OB_FREIGHT_PCT,
FISCAL_MO AS FISCAL_MO,
FROM_LOCATION_ID AS FROM_LOCATION_ID,
INS_UPD_FLAG AS INS_UPD_FLAG,
LOAD_TSTMP AS LOAD_TSTMP,
Monotonically_Increasing_Id AS Monotonically_Increasing_Id,
R12_NET_SALES_COST AS R12_NET_SALES_COST,
R12_OB_FREIGHT_COST AS R12_OB_FREIGHT_COST,
R12_OB_FREIGHT_PCT AS R12_OB_FREIGHT_PCT,
UPDATE_TSTMP AS UPDATE_TSTMP FROM EXP_INSERT_12 UNION ALL SELECT ACT_NET_SALES_COST AS ACT_NET_SALES_COST,
ACT_OB_FREIGHT_COST AS ACT_OB_FREIGHT_COST,
ACT_OB_FREIGHT_PCT AS ACT_OB_FREIGHT_PCT,
FISCAL_MO AS FISCAL_MO,
FROM_LOCATION_ID AS FROM_LOCATION_ID,
INS_UPD_FLAG AS INS_UPD_FLAG,
LOAD_TSTMP AS LOAD_TSTMP,
Monotonically_Increasing_Id AS Monotonically_Increasing_Id,
R12_NET_SALES_COST AS R12_NET_SALES_COST,
R12_OB_FREIGHT_COST AS R12_OB_FREIGHT_COST,
R12_OB_FREIGHT_PCT AS R12_OB_FREIGHT_PCT,
UPDATE_TSTMP AS UPDATE_TSTMP FROM EXP_UPDATE_10""")

df_13.createOrReplaceTempView("UNI_OB_FREIGHT_13")

# COMMAND ----------
# DBTITLE 1, UPD_STRATEGY_14


df_14=spark.sql("""
    SELECT
        FROM_LOCATION_ID AS FROM_LOCATION_ID,
        FISCAL_MO AS FISCAL_MO,
        R12_NET_SALES_COST AS R12_NET_SALES_COST,
        R12_OB_FREIGHT_COST AS R12_OB_FREIGHT_COST,
        R12_OB_FREIGHT_PCT AS R12_OB_FREIGHT_PCT,
        ACT_NET_SALES_COST AS ACT_NET_SALES_COST,
        ACT_OB_FREIGHT_COST AS ACT_OB_FREIGHT_COST,
        ACT_OB_FREIGHT_PCT AS ACT_OB_FREIGHT_PCT,
        UPDATE_TSTMP AS UPDATE_TSTMP,
        LOAD_TSTMP AS LOAD_TSTMP,
        INS_UPD_FLAG AS INS_UPD_FLAG,
        Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        UNI_OB_FREIGHT_13""")

df_14.createOrReplaceTempView("UPD_STRATEGY_14")

# COMMAND ----------
# DBTITLE 1, SITE_PROFILE_15


df_15=spark.sql("""
    SELECT
        LOCATION_ID AS LOCATION_ID,
        LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
        STORE_NBR AS STORE_NBR,
        STORE_NAME AS STORE_NAME,
        STORE_TYPE_ID AS STORE_TYPE_ID,
        STORE_OPEN_CLOSE_FLAG AS STORE_OPEN_CLOSE_FLAG,
        COMPANY_ID AS COMPANY_ID,
        REGION_ID AS REGION_ID,
        DISTRICT_ID AS DISTRICT_ID,
        PRICE_ZONE_ID AS PRICE_ZONE_ID,
        PRICE_AD_ZONE_ID AS PRICE_AD_ZONE_ID,
        REPL_DC_NBR AS REPL_DC_NBR,
        REPL_FISH_DC_NBR AS REPL_FISH_DC_NBR,
        REPL_FWD_DC_NBR AS REPL_FWD_DC_NBR,
        SQ_FEET_RETAIL AS SQ_FEET_RETAIL,
        SQ_FEET_TOTAL AS SQ_FEET_TOTAL,
        SITE_ADDRESS AS SITE_ADDRESS,
        SITE_CITY AS SITE_CITY,
        STATE_CD AS STATE_CD,
        COUNTRY_CD AS COUNTRY_CD,
        POSTAL_CD AS POSTAL_CD,
        SITE_MAIN_TELE_NO AS SITE_MAIN_TELE_NO,
        SITE_GROOM_TELE_NO AS SITE_GROOM_TELE_NO,
        SITE_EMAIL_ADDRESS AS SITE_EMAIL_ADDRESS,
        SITE_SALES_FLAG AS SITE_SALES_FLAG,
        EQUINE_MERCH_ID AS EQUINE_MERCH_ID,
        EQUINE_SITE_ID AS EQUINE_SITE_ID,
        EQUINE_SITE_OPEN_DT AS EQUINE_SITE_OPEN_DT,
        GEO_LATITUDE_NBR AS GEO_LATITUDE_NBR,
        GEO_LONGITUDE_NBR AS GEO_LONGITUDE_NBR,
        PETSMART_DMA_CD AS PETSMART_DMA_CD,
        LOYALTY_PGM_TYPE_ID AS LOYALTY_PGM_TYPE_ID,
        LOYALTY_PGM_STATUS_ID AS LOYALTY_PGM_STATUS_ID,
        LOYALTY_PGM_START_DT AS LOYALTY_PGM_START_DT,
        LOYALTY_PGM_CHANGE_DT AS LOYALTY_PGM_CHANGE_DT,
        BP_COMPANY_NBR AS BP_COMPANY_NBR,
        BP_GL_ACCT AS BP_GL_ACCT,
        TP_LOC_FLAG AS TP_LOC_FLAG,
        TP_ACTIVE_CNT AS TP_ACTIVE_CNT,
        PROMO_LABEL_CD AS PROMO_LABEL_CD,
        PARENT_LOCATION_ID AS PARENT_LOCATION_ID,
        LOCATION_NBR AS LOCATION_NBR,
        TIME_ZONE_ID AS TIME_ZONE_ID,
        DELV_SERVICE_CLASS_ID AS DELV_SERVICE_CLASS_ID,
        PICK_SERVICE_CLASS_ID AS PICK_SERVICE_CLASS_ID,
        SITE_LOGIN_ID AS SITE_LOGIN_ID,
        SITE_MANAGER_ID AS SITE_MANAGER_ID,
        SITE_OPEN_YRS_AMT AS SITE_OPEN_YRS_AMT,
        HOTEL_FLAG AS HOTEL_FLAG,
        DAYCAMP_FLAG AS DAYCAMP_FLAG,
        VET_FLAG AS VET_FLAG,
        DIST_MGR_NAME AS DIST_MGR_NAME,
        DIST_SVC_MGR_NAME AS DIST_SVC_MGR_NAME,
        REGION_VP_NAME AS REGION_VP_NAME,
        REGION_TRAINER_NAME AS REGION_TRAINER_NAME,
        ASSET_PROTECT_NAME AS ASSET_PROTECT_NAME,
        SITE_COUNTY AS SITE_COUNTY,
        SITE_FAX_NO AS SITE_FAX_NO,
        SFT_OPEN_DT AS SFT_OPEN_DT,
        DM_EMAIL_ADDRESS AS DM_EMAIL_ADDRESS,
        DSM_EMAIL_ADDRESS AS DSM_EMAIL_ADDRESS,
        RVP_EMAIL_ADDRESS AS RVP_EMAIL_ADDRESS,
        TRADE_AREA AS TRADE_AREA,
        FDLPS_NAME AS FDLPS_NAME,
        FDLPS_EMAIL AS FDLPS_EMAIL,
        OVERSITE_MGR_NAME AS OVERSITE_MGR_NAME,
        OVERSITE_MGR_EMAIL AS OVERSITE_MGR_EMAIL,
        SAFETY_DIRECTOR_NAME AS SAFETY_DIRECTOR_NAME,
        SAFETY_DIRECTOR_EMAIL AS SAFETY_DIRECTOR_EMAIL,
        RETAIL_MANAGER_SAFETY_NAME AS RETAIL_MANAGER_SAFETY_NAME,
        RETAIL_MANAGER_SAFETY_EMAIL AS RETAIL_MANAGER_SAFETY_EMAIL,
        AREA_DIRECTOR_NAME AS AREA_DIRECTOR_NAME,
        AREA_DIRECTOR_EMAIL AS AREA_DIRECTOR_EMAIL,
        DC_GENERAL_MANAGER_NAME AS DC_GENERAL_MANAGER_NAME,
        DC_GENERAL_MANAGER_EMAIL AS DC_GENERAL_MANAGER_EMAIL,
        ASST_DC_GENERAL_MANAGER_NAME1 AS ASST_DC_GENERAL_MANAGER_NAME1,
        ASST_DC_GENERAL_MANAGER_EMAIL1 AS ASST_DC_GENERAL_MANAGER_EMAIL1,
        ASST_DC_GENERAL_MANAGER_NAME2 AS ASST_DC_GENERAL_MANAGER_NAME2,
        ASST_DC_GENERAL_MANAGER_EMAIL2 AS ASST_DC_GENERAL_MANAGER_EMAIL2,
        REGIONAL_DC_SAFETY_MGR_NAME AS REGIONAL_DC_SAFETY_MGR_NAME,
        REGIONAL_DC_SAFETY_MGR_EMAIL AS REGIONAL_DC_SAFETY_MGR_EMAIL,
        DC_PEOPLE_SUPERVISOR_NAME AS DC_PEOPLE_SUPERVISOR_NAME,
        DC_PEOPLE_SUPERVISOR_EMAIL AS DC_PEOPLE_SUPERVISOR_EMAIL,
        PEOPLE_MANAGER_NAME AS PEOPLE_MANAGER_NAME,
        PEOPLE_MANAGER_EMAIL AS PEOPLE_MANAGER_EMAIL,
        ASSET_PROT_DIR_NAME AS ASSET_PROT_DIR_NAME,
        ASSET_PROT_DIR_EMAIL AS ASSET_PROT_DIR_EMAIL,
        SR_REG_ASSET_PROT_MGR_NAME AS SR_REG_ASSET_PROT_MGR_NAME,
        SR_REG_ASSET_PROT_MGR_EMAIL AS SR_REG_ASSET_PROT_MGR_EMAIL,
        REG_ASSET_PROT_MGR_NAME AS REG_ASSET_PROT_MGR_NAME,
        REG_ASSET_PROT_MGR_EMAIL AS REG_ASSET_PROT_MGR_EMAIL,
        ASSET_PROTECT_EMAIL AS ASSET_PROTECT_EMAIL,
        TP_START_DT AS TP_START_DT,
        OPEN_DT AS OPEN_DT,
        GR_OPEN_DT AS GR_OPEN_DT,
        CLOSE_DT AS CLOSE_DT,
        HOTEL_OPEN_DT AS HOTEL_OPEN_DT,
        ADD_DT AS ADD_DT,
        DELETE_DT AS DELETE_DT,
        UPDATE_DT AS UPDATE_DT,
        LOAD_DT AS LOAD_DT,
        monotonically_increasing_id() AS Monotonically_Increasing_Id 
    FROM
        SITE_PROFILE""")

df_15.createOrReplaceTempView("SITE_PROFILE_15")

# COMMAND ----------
# DBTITLE 1, GL_ACTUAL_DETAIL_16


df_16=spark.sql("""
    SELECT
        FISCAL_YR AS FISCAL_YR,
        FISCAL_MO AS FISCAL_MO,
        GL_DOCUMENT_NBR AS GL_DOCUMENT_NBR,
        GL_COMPANY_CD AS GL_COMPANY_CD,
        GL_DOCUMENT_LINE_NBR AS GL_DOCUMENT_LINE_NBR,
        FISCAL_WK AS FISCAL_WK,
        WEEK_DT AS WEEK_DT,
        GL_DOCUMENT_DT AS GL_DOCUMENT_DT,
        GL_POSTING_DT AS GL_POSTING_DT,
        GL_DOCUMENT_ENTRY_DT AS GL_DOCUMENT_ENTRY_DT,
        GL_DOCUMENT_TYPE_CD AS GL_DOCUMENT_TYPE_CD,
        GL_REF_DOCUMENT_NBR AS GL_REF_DOCUMENT_NBR,
        GL_PROFIT_CENTER_GID AS GL_PROFIT_CENTER_GID,
        LOCATION_ID AS LOCATION_ID,
        STORE_NBR AS STORE_NBR,
        GL_DEPARTMENT_CD AS GL_DEPARTMENT_CD,
        GL_DEBIT_CREDIT_IND AS GL_DEBIT_CREDIT_IND,
        GL_ACCOUNT_GID AS GL_ACCOUNT_GID,
        GL_BALANCE_SHEET_IND AS GL_BALANCE_SHEET_IND,
        GL_PL_SHEET_IND AS GL_PL_SHEET_IND,
        GL_SPLIT_LINE_ITEM_IND AS GL_SPLIT_LINE_ITEM_IND,
        GL_BUSINESS_TXN_TYPE_CD AS GL_BUSINESS_TXN_TYPE_CD,
        GL_REF_TXN_TYPE_CD AS GL_REF_TXN_TYPE_CD,
        GL_TXN_TYPE_CD AS GL_TXN_TYPE_CD,
        GL_COST_ELEMENT_CD AS GL_COST_ELEMENT_CD,
        GL_POSTING_KEY_GID AS GL_POSTING_KEY_GID,
        GL_CONTROLLING_AREA AS GL_CONTROLLING_AREA,
        GL_SEGMENT_CD AS GL_SEGMENT_CD,
        GL_PARTNER_PROFIT_CENTER_GID AS GL_PARTNER_PROFIT_CENTER_GID,
        GL_PARTNER_COMPANY_CD AS GL_PARTNER_COMPANY_CD,
        GL_PARTNER_SEGMENT_CD AS GL_PARTNER_SEGMENT_CD,
        VENDOR_ID AS VENDOR_ID,
        GL_ITEM_CATEGORY_CD AS GL_ITEM_CATEGORY_CD,
        GL_PURCH_DOC_NBR AS GL_PURCH_DOC_NBR,
        GL_DOC_CURRENCY_ID AS GL_DOC_CURRENCY_ID,
        GL_DOC_AMT AS GL_DOC_AMT,
        GL_LOC_CURRENCY_ID AS GL_LOC_CURRENCY_ID,
        GL_LOC_AMT AS GL_LOC_AMT,
        GL_GRP_CURRENCY_ID AS GL_GRP_CURRENCY_ID,
        GL_GRP_AMT AS GL_GRP_AMT,
        GL_QTY AS GL_QTY,
        GL_QTY_UOM_CD AS GL_QTY_UOM_CD,
        EXCH_RATE_PCT AS EXCH_RATE_PCT,
        GL_USER_NAME AS GL_USER_NAME,
        GL_LOAD_TSTMP AS GL_LOAD_TSTMP,
        UPDATE_DT AS UPDATE_DT,
        LOAD_DT AS LOAD_DT,
        monotonically_increasing_id() AS Monotonically_Increasing_Id 
    FROM
        GL_ACTUAL_DETAIL""")

df_16.createOrReplaceTempView("GL_ACTUAL_DETAIL_16")

# COMMAND ----------
# DBTITLE 1, MA_OB_FREIGHT_CTRL


spark.sql("""INSERT INTO MA_OB_FREIGHT_CTRL SELECT FROM_LOCATION_ID AS FROM_LOCATION_ID,
FISCAL_MO AS FISCAL_MO,
R12_NET_SALES_COST AS R12_NET_SALES_COST,
R12_OB_FREIGHT_COST AS R12_OB_FREIGHT_COST,
R12_OB_FREIGHT_PCT AS R12_OB_FREIGHT_PCT,
ACT_NET_SALES_COST AS ACT_NET_SALES_COST,
ACT_OB_FREIGHT_COST AS ACT_OB_FREIGHT_COST,
ACT_OB_FREIGHT_PCT AS ACT_OB_FREIGHT_PCT,
UPDATE_TSTMP AS UPDATE_TSTMP,
LOAD_TSTMP AS LOAD_TSTMP FROM UPD_STRATEGY_14""")