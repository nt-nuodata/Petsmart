{"Edges":[{"transformationType":"Source Definition","id":"e-0","source":"","target":"SERVICES_MARGIN_RATE_PRE"},{"transformationType":"Source Definition","id":"e-1","source":"","target":"SERVICES_MARGIN_RATE"},{"transformationType":"Source Definition","id":"e-2","source":"","target":"DAYS"},{"transformationType":"Source Qualifier","id":"e-3","source":"DAYS","target":"SQ_Shortcut_to_SERVICES_MARGIN_RATE"},{"transformationType":"Source Qualifier","id":"e-4","source":"SERVICES_MARGIN_RATE","target":"SQ_Shortcut_to_SERVICES_MARGIN_RATE"},{"transformationType":"Expression","id":"e-5","source":"SQ_Shortcut_to_SERVICES_MARGIN_RATE","target":"EXP_ESTIMATE"},{"transformationType":"Update Strategy","id":"e-6","source":"EXP_ESTIMATE","target":"UPD_STRATEGY"},{"transformationType":"Target Definition","id":"e-7","source":"UPD_STRATEGY","target":"SERVICES_MARGIN_RATE"}],"Nodes":[{"data":{"transformationType":"Source Definition","label":"SERVICES_MARGIN_RATE_PRE","queries":["df_0=spark.sql(\"\"\"\n    SELECT\n        WEEK_DT AS WEEK_DT,\n        LOCATION_ID AS LOCATION_ID,\n        SAP_DEPT_ID AS SAP_DEPT_ID,\n        MARGIN_RATE AS MARGIN_RATE,\n        monotonically_increasing_id() AS Monotonically_Increasing_Id \n    FROM\n        SERVICES_MARGIN_RATE_PRE\"\"\")","df_0.createOrReplaceTempView(\"SERVICES_MARGIN_RATE_PRE_0\")"]},"id":"SERVICES_MARGIN_RATE_PRE","position":{"x":0,"y":0},"type":"normalNode"},{"data":{"transformationType":"Source Definition","label":"SERVICES_MARGIN_RATE","queries":["df_1=spark.sql(\"\"\"\n    SELECT\n        WEEK_DT AS WEEK_DT,\n        LOCATION_ID AS LOCATION_ID,\n        SAP_DEPT_ID AS SAP_DEPT_ID,\n        MARGIN_RATE AS MARGIN_RATE,\n        UPDATE_TSTMP AS UPDATE_TSTMP,\n        LOAD_TSTMP AS LOAD_TSTMP,\n        monotonically_increasing_id() AS Monotonically_Increasing_Id \n    FROM\n        SERVICES_MARGIN_RATE\"\"\")","df_1.createOrReplaceTempView(\"SERVICES_MARGIN_RATE_1\")"]},"id":"SERVICES_MARGIN_RATE","position":{"x":0,"y":0},"type":"normalNode"},{"data":{"transformationType":"Source Definition","label":"DAYS","queries":["df_2=spark.sql(\"\"\"\n    SELECT\n        DAY_DT AS DAY_DT,\n        BUSINESS_DAY_FLAG AS BUSINESS_DAY_FLAG,\n        HOLIDAY_FLAG AS HOLIDAY_FLAG,\n        DAY_OF_WK_NAME AS DAY_OF_WK_NAME,\n        DAY_OF_WK_NAME_ABBR AS DAY_OF_WK_NAME_ABBR,\n        DAY_OF_WK_NBR AS DAY_OF_WK_NBR,\n        CAL_DAY_OF_MO_NBR AS CAL_DAY_OF_MO_NBR,\n        CAL_DAY_OF_YR_NBR AS CAL_DAY_OF_YR_NBR,\n        CAL_WK AS CAL_WK,\n        CAL_WK_NBR AS CAL_WK_NBR,\n        CAL_MO AS CAL_MO,\n        CAL_MO_NBR AS CAL_MO_NBR,\n        CAL_MO_NAME AS CAL_MO_NAME,\n        CAL_MO_NAME_ABBR AS CAL_MO_NAME_ABBR,\n        CAL_QTR AS CAL_QTR,\n        CAL_QTR_NBR AS CAL_QTR_NBR,\n        CAL_HALF AS CAL_HALF,\n        CAL_YR AS CAL_YR,\n        FISCAL_DAY_OF_MO_NBR AS FISCAL_DAY_OF_MO_NBR,\n        FISCAL_DAY_OF_YR_NBR AS FISCAL_DAY_OF_YR_NBR,\n        FISCAL_WK AS FISCAL_WK,\n        FISCAL_WK_NBR AS FISCAL_WK_NBR,\n        FISCAL_MO AS FISCAL_MO,\n        FISCAL_MO_NBR AS FISCAL_MO_NBR,\n        FISCAL_MO_NAME AS FISCAL_MO_NAME,\n        FISCAL_MO_NAME_ABBR AS FISCAL_MO_NAME_ABBR,\n        FISCAL_QTR AS FISCAL_QTR,\n        FISCAL_QTR_NBR AS FISCAL_QTR_NBR,\n        FISCAL_HALF AS FISCAL_HALF,\n        FISCAL_YR AS FISCAL_YR,\n        LYR_WEEK_DT AS LYR_WEEK_DT,\n        LWK_WEEK_DT AS LWK_WEEK_DT,\n        WEEK_DT AS WEEK_DT,\n        EST_TIME_CONV_AMT AS EST_TIME_CONV_AMT,\n        EST_TIME_CONV_HRS AS EST_TIME_CONV_HRS,\n        ES0_TIME_CONV_AMT AS ES0_TIME_CONV_AMT,\n        ES0_TIME_CONV_HRS AS ES0_TIME_CONV_HRS,\n        CST_TIME_CONV_AMT AS CST_TIME_CONV_AMT,\n        CST_TIME_CONV_HRS AS CST_TIME_CONV_HRS,\n        CS0_TIME_CONV_AMT AS CS0_TIME_CONV_AMT,\n        CS0_TIME_CONV_HRS AS CS0_TIME_CONV_HRS,\n        MST_TIME_CONV_AMT AS MST_TIME_CONV_AMT,\n        MST_TIME_CONV_HRS AS MST_TIME_CONV_HRS,\n        MS0_TIME_CONV_AMT AS MS0_TIME_CONV_AMT,\n        MS0_TIME_CONV_HRS AS MS0_TIME_CONV_HRS,\n        PST_TIME_CONV_AMT AS PST_TIME_CONV_AMT,\n        PST_TIME_CONV_HRS AS PST_TIME_CONV_HRS,\n        monotonically_increasing_id() AS Monotonically_Increasing_Id \n    FROM\n        DAYS\"\"\")","df_2.createOrReplaceTempView(\"DAYS_2\")"]},"id":"DAYS","position":{"x":0,"y":0},"type":"normalNode"},{"data":{"transformationType":"Source Qualifier","label":"SQ_Shortcut_to_SERVICES_MARGIN_RATE","queries":["df_3=spark.sql(\"\"\"WITH LATEST_RATE AS(\r\nSELECT P.LOCATION_ID,\r\n       P.SAP_DEPT_ID,\r\n       CASE WHEN P.MARGIN_RATE > 1.0  \r\n            THEN 1.0\r\n            WHEN P.MARGIN_RATE < -1.0  \r\n            THEN -1.0\r\n            ELSE P.MARGIN_RATE\r\n        END MARGIN_RATE\r\n  FROM (\r\n       SELECT LOCATION_ID, \r\n              SAP_DEPT_ID,\r\n              MAX(WEEK_DT) AS LATEST_WEEK_DT\r\n         FROM SERVICES_MARGIN_RATE\r\n        WHERE WEEK_DT <= (SELECT MAX(WEEK_DT) FROM SERVICES_MARGIN_RATE_PRE)\r\n        GROUP BY LOCATION_ID, \r\n              SAP_DEPT_ID\r\n       ) S,\r\n       SERVICES_MARGIN_RATE P\r\n  WHERE S.LOCATION_ID    = P.LOCATION_ID\r\n    AND S.SAP_DEPT_ID    = P.SAP_DEPT_ID\r\n    AND S.LATEST_WEEK_DT = P.WEEK_DT\r\n)\r\n    \r\nSELECT M.WEEK_DT,\r\n       M.LOCATION_ID,\r\n       M.SAP_DEPT_ID,\r\n       NVL(L.MARGIN_RATE,0.0000) AS MARGIN_RATE,\r\n       M.LOAD_TSTMP,\r\n       'U' as LOAD_FLAG\r\n  FROM SERVICES_MARGIN_RATE M\r\n  LEFT JOIN LATEST_RATE L\r\n    ON L.LOCATION_ID = M.LOCATION_ID\r\n   AND L.SAP_DEPT_ID = M.SAP_DEPT_ID\r\n WHERE WEEK_DT > (SELECT MAX(WEEK_DT) FROM SERVICES_MARGIN_RATE_PRE)\r\n   AND M.MARGIN_RATE <> NVL(L.MARGIN_RATE,0.0000)\r\n \r\nUNION ALL\r\n\r\nSELECT TT.WEEK_DT,\r\n       TT.LOCATION_ID,\r\n       TT.SAP_DEPT_ID,\r\n       TT.MARGIN_RATE,\r\n       CURRENT_TIMESTAMP AS LOAD_TSTMP,\r\n       'I' as LOAD_FLAG\r\n  FROM (\r\n       SELECT W.WEEK_DT,\r\n              L.LOCATION_ID,\r\n              L.SAP_DEPT_ID,\r\n              L.MARGIN_RATE\r\n         FROM (\r\n              SELECT DISTINCT WEEK_DT\r\n                FROM DAYS \r\n               WHERE DAY_DT BETWEEN (SELECT CAST(MAX(WEEK_DT) AS DATE) + 1 FROM SERVICES_MARGIN_RATE_PRE) \r\n                 AND CURRENT_DATE + 7\r\n              ) W,\r\n              LATEST_RATE L\r\n       ) TT\r\n  LEFT JOIN SERVICES_MARGIN_RATE M\r\n    ON TT.WEEK_DT     = M.WEEK_DT\r\n   AND TT.LOCATION_ID = M.LOCATION_ID\r\n   AND TT.SAP_DEPT_ID = M.SAP_DEPT_ID\r\n WHERE M.WEEK_DT IS NULL\"\"\")","df_3.createOrReplaceTempView(\"SQ_Shortcut_to_SERVICES_MARGIN_RATE_3\")"]},"id":"SQ_Shortcut_to_SERVICES_MARGIN_RATE","position":{"x":0,"y":0},"type":"normalNode"},{"data":{"transformationType":"Source Qualifier","label":"SQ_Shortcut_to_SERVICES_MARGIN_RATE","queries":["df_3=spark.sql(\"\"\"WITH LATEST_RATE AS(\r\nSELECT P.LOCATION_ID,\r\n       P.SAP_DEPT_ID,\r\n       CASE WHEN P.MARGIN_RATE > 1.0  \r\n            THEN 1.0\r\n            WHEN P.MARGIN_RATE < -1.0  \r\n            THEN -1.0\r\n            ELSE P.MARGIN_RATE\r\n        END MARGIN_RATE\r\n  FROM (\r\n       SELECT LOCATION_ID, \r\n              SAP_DEPT_ID,\r\n              MAX(WEEK_DT) AS LATEST_WEEK_DT\r\n         FROM SERVICES_MARGIN_RATE\r\n        WHERE WEEK_DT <= (SELECT MAX(WEEK_DT) FROM SERVICES_MARGIN_RATE_PRE)\r\n        GROUP BY LOCATION_ID, \r\n              SAP_DEPT_ID\r\n       ) S,\r\n       SERVICES_MARGIN_RATE P\r\n  WHERE S.LOCATION_ID    = P.LOCATION_ID\r\n    AND S.SAP_DEPT_ID    = P.SAP_DEPT_ID\r\n    AND S.LATEST_WEEK_DT = P.WEEK_DT\r\n)\r\n    \r\nSELECT M.WEEK_DT,\r\n       M.LOCATION_ID,\r\n       M.SAP_DEPT_ID,\r\n       NVL(L.MARGIN_RATE,0.0000) AS MARGIN_RATE,\r\n       M.LOAD_TSTMP,\r\n       'U' as LOAD_FLAG\r\n  FROM SERVICES_MARGIN_RATE M\r\n  LEFT JOIN LATEST_RATE L\r\n    ON L.LOCATION_ID = M.LOCATION_ID\r\n   AND L.SAP_DEPT_ID = M.SAP_DEPT_ID\r\n WHERE WEEK_DT > (SELECT MAX(WEEK_DT) FROM SERVICES_MARGIN_RATE_PRE)\r\n   AND M.MARGIN_RATE <> NVL(L.MARGIN_RATE,0.0000)\r\n \r\nUNION ALL\r\n\r\nSELECT TT.WEEK_DT,\r\n       TT.LOCATION_ID,\r\n       TT.SAP_DEPT_ID,\r\n       TT.MARGIN_RATE,\r\n       CURRENT_TIMESTAMP AS LOAD_TSTMP,\r\n       'I' as LOAD_FLAG\r\n  FROM (\r\n       SELECT W.WEEK_DT,\r\n              L.LOCATION_ID,\r\n              L.SAP_DEPT_ID,\r\n              L.MARGIN_RATE\r\n         FROM (\r\n              SELECT DISTINCT WEEK_DT\r\n                FROM DAYS \r\n               WHERE DAY_DT BETWEEN (SELECT CAST(MAX(WEEK_DT) AS DATE) + 1 FROM SERVICES_MARGIN_RATE_PRE) \r\n                 AND CURRENT_DATE + 7\r\n              ) W,\r\n              LATEST_RATE L\r\n       ) TT\r\n  LEFT JOIN SERVICES_MARGIN_RATE M\r\n    ON TT.WEEK_DT     = M.WEEK_DT\r\n   AND TT.LOCATION_ID = M.LOCATION_ID\r\n   AND TT.SAP_DEPT_ID = M.SAP_DEPT_ID\r\n WHERE M.WEEK_DT IS NULL\"\"\")","df_3.createOrReplaceTempView(\"SQ_Shortcut_to_SERVICES_MARGIN_RATE_3\")"]},"id":"SQ_Shortcut_to_SERVICES_MARGIN_RATE","position":{"x":0,"y":0},"type":"normalNode"},{"data":{"transformationType":"Expression","label":"EXP_ESTIMATE","queries":["df_4=spark.sql(\"\"\"\n    SELECT\n        WEEK_DT AS WEEK_DT,\n        LOCATION_ID AS LOCATION_ID,\n        SAP_DEPT_ID AS SAP_DEPT_ID,\n        MARGIN_RATE AS MARGIN_RATE,\n        current_timestamp AS UPDATE_TSTMP,\n        IFF(LOAD_FLAG = 'I',\n        current_timestamp,\n        LOAD_TSTMP) AS LOAD_TSTMP,\n        LOAD_FLAG AS LOAD_FLAG,\n        Monotonically_Increasing_Id AS Monotonically_Increasing_Id \n    FROM\n        SQ_Shortcut_to_SERVICES_MARGIN_RATE_3\"\"\")","df_4.createOrReplaceTempView(\"EXP_ESTIMATE_4\")"]},"id":"EXP_ESTIMATE","position":{"x":0,"y":0},"type":"normalNode"},{"data":{"transformationType":"Update Strategy","label":"UPD_STRATEGY","queries":["df_5=spark.sql(\"\"\"\n    SELECT\n        WEEK_DT AS WEEK_DT,\n        LOCATION_ID AS LOCATION_ID,\n        SAP_DEPT_ID AS SAP_DEPT_ID,\n        MARGIN_RATE AS MARGIN_RATE,\n        UPDATE_TSTMP AS UPDATE_TSTMP,\n        LOAD_TSTMP AS LOAD_TSTMP,\n        LOAD_FLAG AS LOAD_FLAG,\n        Monotonically_Increasing_Id AS Monotonically_Increasing_Id \n    FROM\n        EXP_ESTIMATE_4\"\"\")","df_5.createOrReplaceTempView(\"UPD_STRATEGY_5\")"]},"id":"UPD_STRATEGY","position":{"x":0,"y":0},"type":"normalNode"},{"data":{"transformationType":"Target Definition","label":"SERVICES_MARGIN_RATE","queries":["spark.sql(\"\"\"INSERT INTO SERVICES_MARGIN_RATE SELECT WEEK_DT AS WEEK_DT,\nLOCATION_ID AS LOCATION_ID,\nSAP_DEPT_ID AS SAP_DEPT_ID,\nMARGIN_RATE AS MARGIN_RATE,\nUPDATE_TSTMP AS UPDATE_TSTMP,\nLOAD_TSTMP AS LOAD_TSTMP FROM UPD_STRATEGY_5\"\"\")"]},"id":"SERVICES_MARGIN_RATE","position":{"x":0,"y":0},"type":"normalNode"}]}