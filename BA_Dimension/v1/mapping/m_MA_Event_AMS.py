# Databricks notebook source
# MAGIC %run "./udf_informatica"

# COMMAND ----------


from pyspark.sql.types import *

spark.sql("use DELTA_TRAINING")
spark.sql("set spark.sql.legacy.timeParserPolicy = LEGACY")


# COMMAND ----------
# DBTITLE 1, MA_EVENT_AMS_PRE_0


df_0=spark.sql("""
    SELECT
        MA_EVENT_ID AS MA_EVENT_ID,
        OFFER_ID AS OFFER_ID,
        START_DT AS START_DT,
        END_DT AS END_DT,
        MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
        MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
        MA_EVENT_DESC AS MA_EVENT_DESC,
        MA_PCT_IND AS MA_PCT_IND,
        MA_AMT AS MA_AMT,
        MA_MAX_AMT AS MA_MAX_AMT,
        OFFER_AS_DISC_IND AS OFFER_AS_DISC_IND,
        VENDOR_FUNDED_IND AS VENDOR_FUNDED_IND,
        VENDOR_NAME_TXT AS VENDOR_NAME_TXT,
        INSERT_FLAG AS INSERT_FLAG,
        DELETE_FLAG AS DELETE_FLAG,
        monotonically_increasing_id() AS Monotonically_Increasing_Id 
    FROM
        MA_EVENT_AMS_PRE""")

df_0.createOrReplaceTempView("MA_EVENT_AMS_PRE_0")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_MA_EVENT_AMS_PRE_1


df_1=spark.sql("""
    SELECT
        MA_EVENT_ID AS MA_EVENT_ID,
        OFFER_ID AS OFFER_ID,
        START_DT AS START_DT,
        END_DT AS END_DT,
        MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
        MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
        MA_EVENT_DESC AS MA_EVENT_DESC,
        MA_PCT_IND AS MA_PCT_IND,
        MA_AMT AS MA_AMT,
        MA_MAX_AMT AS MA_MAX_AMT,
        VENDOR_NAME_TXT AS VENDOR_NAME_TXT,
        Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        MA_EVENT_AMS_PRE_0 
    WHERE
        MA_EVENT_AMS_PRE.INSERT_FLAG = 1""")

df_1.createOrReplaceTempView("SQ_Shortcut_to_MA_EVENT_AMS_PRE_1")

# COMMAND ----------
# DBTITLE 1, EXP_DeriveLoadFlag_2


df_2=spark.sql("""
    SELECT
        MA_EVENT_ID AS MA_EVENT_ID,
        OFFER_ID AS OFFER_ID,
        START_DT AS START_DT,
        END_DT AS END_DT,
        MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
        MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
        MA_EVENT_DESC AS MA_EVENT_DESC,
        MA_PCT_IND AS MA_PCT_IND,
        MA_AMT AS MA_AMT,
        MA_MAX_AMT AS MA_MAX_AMT,
        VENDOR_NAME_TXT AS VENDOR_NAME_TXT,
        'I' AS LOAD_FLG,
        Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        SQ_Shortcut_to_MA_EVENT_AMS_PRE_1""")

df_2.createOrReplaceTempView("EXP_DeriveLoadFlag_2")

# COMMAND ----------
# DBTITLE 1, MA_EVENT_3


df_3=spark.sql("""
    SELECT
        MA_EVENT_ID AS MA_EVENT_ID,
        OFFER_ID AS OFFER_ID,
        SAP_DEPT_ID AS SAP_DEPT_ID,
        PRODUCT_ID AS PRODUCT_ID,
        COUNTRY_CD AS COUNTRY_CD,
        START_DT AS START_DT,
        END_DT AS END_DT,
        MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
        MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
        LOCATION_ID AS LOCATION_ID,
        MOVEMENT_ID AS MOVEMENT_ID,
        VALUATION_CLASS_CD AS VALUATION_CLASS_CD,
        GL_ACCT_NBR AS GL_ACCT_NBR,
        LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
        ROYALTY_BRAND_ID AS ROYALTY_BRAND_ID,
        BRAND_CD AS BRAND_CD,
        MA_FORMULA_CD AS MA_FORMULA_CD,
        FISCAL_MO AS FISCAL_MO,
        SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
        FROM_LOCATION_ID AS FROM_LOCATION_ID,
        SOURCE_VENDOR_ID AS SOURCE_VENDOR_ID,
        COMPANY_ID AS COMPANY_ID,
        MA_EVENT_DESC AS MA_EVENT_DESC,
        EM_VENDOR_FUNDING_ID AS EM_VENDOR_FUNDING_ID,
        EM_COMMENT AS EM_COMMENT,
        EM_BILL_ALT_VENDOR_FLAG AS EM_BILL_ALT_VENDOR_FLAG,
        EM_ALT_VENDOR_ID AS EM_ALT_VENDOR_ID,
        EM_ALT_VENDOR_NAME AS EM_ALT_VENDOR_NAME,
        EM_ALT_VENDOR_COUNTRY_CD AS EM_ALT_VENDOR_COUNTRY_CD,
        EM_VENDOR_ID AS EM_VENDOR_ID,
        EM_VENDOR_NAME AS EM_VENDOR_NAME,
        EM_VENDOR_COUNTRY_CD AS EM_VENDOR_COUNTRY_CD,
        VENDOR_NAME_TXT AS VENDOR_NAME_TXT,
        MA_PCT_IND AS MA_PCT_IND,
        MA_AMT AS MA_AMT,
        MA_MAX_AMT AS MA_MAX_AMT,
        UPDATE_DT AS UPDATE_DT,
        LOAD_DT AS LOAD_DT,
        monotonically_increasing_id() AS Monotonically_Increasing_Id 
    FROM
        MA_EVENT""")

df_3.createOrReplaceTempView("MA_EVENT_3")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_MA_EVENT_4


df_4=spark.sql("""SELECT MA_EVENT.END_DT AS tgt_END_DT,
MA_EVENT.VENDOR_NAME_TXT AS tgt_VENDOR_NAME_TXT,
MA_EVENT.MA_EVENT_ID AS MA_EVENT_ID,
MA_EVENT.MA_EVENT_DESC AS tgt_MA_EVENT_DESC,
MA_EVENT.LOAD_DT AS LOAD_DT,
MA_EVENT.MA_AMT AS tgt_MA_AMT,
MA_EVENT.START_DT AS tgt_START_DT,
MA_EVENT.MA_PCT_IND AS tgt_MA_PCT_IND,
MA_EVENT.MA_MAX_AMT AS tgt_MA_MAX_AMT,
MA_EVENT_AMS_PRE.VENDOR_FUNDED_IND AS VENDOR_FUNDED_IND,
MA_EVENT_AMS_PRE.OFFER_ID AS OFFER_ID,
MA_EVENT_AMS_PRE.OFFER_AS_DISC_IND AS OFFER_AS_DISC_IND,
MA_EVENT_AMS_PRE.MA_PCT_IND AS MA_PCT_IND,
MA_EVENT_AMS_PRE.MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
MA_EVENT_AMS_PRE.MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
MA_EVENT_AMS_PRE.START_DT AS START_DT,
MA_EVENT_AMS_PRE.MA_EVENT_DESC AS MA_EVENT_DESC,
MA_EVENT_AMS_PRE.DELETE_FLAG AS DELETE_FLAG,
MA_EVENT_AMS_PRE.VENDOR_NAME_TXT AS VENDOR_NAME_TXT,
MA_EVENT_AMS_PRE.MA_MAX_AMT AS MA_MAX_AMT,
MA_EVENT_AMS_PRE.MA_AMT AS MA_AMT,
MA_EVENT_AMS_PRE.END_DT AS END_DT,
Monotonically_Increasing_Id AS Monotonically_Increasing_Id FROM MA_EVENT.MA_EVENT_ID = MA_EVENT_AMS_PRE.MA_EVENT_ID WHERE 
MA_EVENT_AMS_PRE.INSERT_FLAG = 0
AND MA_EVENT.MA_EVENT_TYPE_ID = 2
AND MA_EVENT_AMS_PRE.MA_EVENT_SOURCE_ID = 6""")

df_4.createOrReplaceTempView("SQ_Shortcut_to_MA_EVENT_4")

# COMMAND ----------
# DBTITLE 1, EXP_DeriveColumns_5


df_5=spark.sql("""
    SELECT
        MA_EVENT_ID AS MA_EVENT_ID,
        OFFER_ID AS OFFER_ID,
        START_DT AS START_DT,
        END_DT AS END_DT,
        MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
        MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
        MA_EVENT_DESC AS MA_EVENT_DESC,
        MA_PCT_IND AS MA_PCT_IND,
        MA_AMT AS MA_AMT,
        MA_MAX_AMT AS MA_MAX_AMT,
        VENDOR_NAME_TXT AS VENDOR_NAME_TXT,
        DECODE(TRUE,
        VENDOR_FUNDED_IND = 0 
        OR DELETE_FLAG = 1 
        OR OFFER_AS_DISC_IND = 0,
        'D',
        IFF(ISNULL(START_DT),
        TO_DATE('12319999',
        'MMDDYYYY'),
        START_DT) <> IFF(ISNULL(tgt_START_DT),
        TO_DATE('12319999',
        'MMDDYYYY'),
        tgt_START_DT) 
        OR IFF(ISNULL(END_DT),
        TO_DATE('12319999',
        'MMDDYYYY'),
        END_DT) <> IFF(ISNULL(tgt_END_DT),
        TO_DATE('12319999',
        'MMDDYYYY'),
        tgt_END_DT) 
        OR IFF(ISNULL(MA_PCT_IND),
        9,
        MA_PCT_IND) <> IFF(ISNULL(tgt_MA_PCT_IND),
        9,
        tgt_MA_PCT_IND) 
        OR IFF(ISNULL(MA_AMT),
        999999,
        MA_AMT) <> IFF(ISNULL(tgt_MA_AMT),
        999999,
        tgt_MA_AMT),
        'R',
        IFF(ISNULL(MA_EVENT_DESC),
        ' ',
        MA_EVENT_DESC) <> IFF(ISNULL(tgt_MA_EVENT_DESC),
        ' ',
        tgt_MA_EVENT_DESC) 
        OR IFF(ISNULL(VENDOR_NAME_TXT),
        ' ',
        VENDOR_NAME_TXT) <> IFF(ISNULL(tgt_VENDOR_NAME_TXT),
        ' ',
        tgt_VENDOR_NAME_TXT) 
        OR IFF(ISNULL(MA_MAX_AMT),
        999999,
        MA_MAX_AMT) <> IFF(ISNULL(tgt_MA_MAX_AMT),
        999999,
        tgt_MA_MAX_AMT),
        'U',
        'N') AS LOAD_FLAG,
        tgt_MA_MAX_AMT AS tgt_MA_MAX_AMT,
        Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        SQ_Shortcut_to_MA_EVENT_4""")

df_5.createOrReplaceTempView("EXP_DeriveColumns_5")

# COMMAND ----------
# DBTITLE 1, FIL_NoChanges_6


df_6=spark.sql("""
    SELECT
        MA_EVENT_ID AS MA_EVENT_ID,
        OFFER_ID AS OFFER_ID,
        START_DT AS START_DT,
        END_DT AS END_DT,
        MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
        MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
        MA_EVENT_DESC AS MA_EVENT_DESC,
        MA_PCT_IND AS MA_PCT_IND,
        MA_AMT AS MA_AMT,
        MA_MAX_AMT AS MA_MAX_AMT,
        VENDOR_NAME_TXT AS VENDOR_NAME_TXT,
        LOAD_FLAG AS LOAD_FLAG,
        Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        EXP_DeriveColumns_5 
    WHERE
        LOAD_FLAG <> 'N'""")

df_6.createOrReplaceTempView("FIL_NoChanges_6")

# COMMAND ----------
# DBTITLE 1, Union_7


df_7=spark.sql("""SELECT END_DT AS END_DT,
LOAD_FLAG AS LOAD_FLG,
MA_AMT AS MA_AMT,
MA_EVENT_DESC AS MA_EVENT_DESC,
MA_EVENT_ID AS MA_EVENT_ID,
MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
MA_MAX_AMT AS MA_MAX_AMT,
MA_PCT_IND AS MA_PCT_IND,
Monotonically_Increasing_Id AS Monotonically_Increasing_Id,
OFFER_ID AS OFFER_ID,
START_DT AS START_DT,
VENDOR_NAME_TXT AS VENDOR_NAME_TXT FROM FIL_NoChanges_6 UNION ALL SELECT END_DT AS END_DT,
LOAD_FLG AS LOAD_FLG,
MA_AMT AS MA_AMT,
MA_EVENT_DESC AS MA_EVENT_DESC,
MA_EVENT_ID AS MA_EVENT_ID,
MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
MA_MAX_AMT AS MA_MAX_AMT,
MA_PCT_IND AS MA_PCT_IND,
Monotonically_Increasing_Id AS Monotonically_Increasing_Id,
OFFER_ID AS OFFER_ID,
START_DT AS START_DT,
VENDOR_NAME_TXT AS VENDOR_NAME_TXT FROM EXP_DeriveLoadFlag_2""")

df_7.createOrReplaceTempView("Union_7")

# COMMAND ----------
# DBTITLE 1, EXP_SetLoadDt2_8


df_8=spark.sql("""
    SELECT
        MA_EVENT_ID AS MA_EVENT_ID,
        OFFER_ID AS OFFER_ID,
        START_DT AS START_DT,
        END_DT AS END_DT,
        MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
        MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
        MA_EVENT_DESC AS MA_EVENT_DESC,
        MA_PCT_IND AS MA_PCT_IND,
        MA_AMT AS MA_AMT,
        MA_MAX_AMT AS MA_MAX_AMT,
        VENDOR_NAME_TXT AS VENDOR_NAME_TXT,
        LOAD_FLG AS LOAD_FLG,
        current_timestamp AS CURRENT_TSTMP,
        Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        Union_7""")

df_8.createOrReplaceTempView("EXP_SetLoadDt2_8")

# COMMAND ----------
# DBTITLE 1, UPD_InsertDeleteOrUpdate_9


df_9=spark.sql("""
    SELECT
        MA_EVENT_ID AS MA_EVENT_ID,
        OFFER_ID AS OFFER_ID,
        START_DT AS START_DT,
        END_DT AS END_DT,
        MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
        MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
        MA_EVENT_DESC AS MA_EVENT_DESC,
        MA_PCT_IND AS MA_PCT_IND,
        MA_AMT AS MA_AMT,
        MA_MAX_AMT AS MA_MAX_AMT,
        VENDOR_NAME_TXT AS VENDOR_NAME_TXT,
        LOAD_FLG AS LOAD_FLG,
        CURRENT_TSTMP AS LOAD_DT,
        CURRENT_TSTMP AS UPDATE_DT,
        Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        EXP_SetLoadDt2_8""")

df_9.createOrReplaceTempView("UPD_InsertDeleteOrUpdate_9")

# COMMAND ----------
# DBTITLE 1, FIL_LoadFlag_10


df_10=spark.sql("""
    SELECT
        MA_EVENT_ID AS MA_EVENT_ID,
        OFFER_ID AS OFFER_ID,
        START_DT AS START_DT,
        END_DT AS END_DT,
        MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
        MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
        MA_EVENT_DESC AS MA_EVENT_DESC,
        MA_PCT_IND AS MA_PCT_IND,
        MA_AMT AS MA_AMT,
        MA_MAX_AMT AS MA_MAX_AMT,
        VENDOR_NAME_TXT AS VENDOR_NAME_TXT,
        LOAD_FLG AS LOAD_FLG,
        Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        Union_7 
    WHERE
        LOAD_FLG = 'D' 
        OR LOAD_FLG = 'R' 
        OR LOAD_FLG = 'I'""")

df_10.createOrReplaceTempView("FIL_LoadFlag_10")

# COMMAND ----------
# DBTITLE 1, EXP_SetLoadDt_11


df_11=spark.sql("""
    SELECT
        MA_EVENT_ID AS MA_EVENT_ID,
        OFFER_ID AS OFFER_ID,
        START_DT AS START_DT,
        END_DT AS END_DT,
        MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
        MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
        MA_EVENT_DESC AS MA_EVENT_DESC,
        MA_PCT_IND AS MA_PCT_IND,
        MA_AMT AS MA_AMT,
        MA_MAX_AMT AS MA_MAX_AMT,
        VENDOR_NAME_TXT AS VENDOR_NAME_TXT,
        IFF(LOAD_FLG = 'R',
        'U',
        LOAD_FLG) AS o_LOAD_FLG,
        date_trunc('DAY',
        current_timestamp) AS LOAD_DT,
        Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        FIL_LoadFlag_10""")

df_11.createOrReplaceTempView("EXP_SetLoadDt_11")

# COMMAND ----------
# DBTITLE 1, UPD_InsertOnly_12


df_12=spark.sql("""
    SELECT
        MA_EVENT_ID AS MA_EVENT_ID,
        OFFER_ID AS OFFER_ID,
        START_DT AS START_DT,
        END_DT AS END_DT,
        MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
        MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
        MA_EVENT_DESC AS MA_EVENT_DESC,
        MA_PCT_IND AS MA_PCT_IND,
        MA_AMT AS MA_AMT,
        MA_MAX_AMT AS MA_MAX_AMT,
        VENDOR_NAME_TXT AS VENDOR_NAME_TXT,
        o_LOAD_FLG AS o_LOAD_FLG,
        LOAD_DT AS LOAD_DT,
        Monotonically_Increasing_Id AS Monotonically_Increasing_Id 
    FROM
        EXP_SetLoadDt_11""")

df_12.createOrReplaceTempView("UPD_InsertOnly_12")

# COMMAND ----------
# DBTITLE 1, MA_EVENT


spark.sql("""INSERT INTO MA_EVENT SELECT MA_EVENT_ID AS MA_EVENT_ID,
OFFER_ID AS OFFER_ID,
SAP_DEPT_ID AS SAP_DEPT_ID,
PRODUCT_ID AS PRODUCT_ID,
COUNTRY_CD AS COUNTRY_CD,
START_DT AS START_DT,
END_DT AS END_DT,
MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
LOCATION_ID AS LOCATION_ID,
MOVEMENT_ID AS MOVEMENT_ID,
VALUATION_CLASS_CD AS VALUATION_CLASS_CD,
GL_ACCT_NBR AS GL_ACCT_NBR,
LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
ROYALTY_BRAND_ID AS ROYALTY_BRAND_ID,
BRAND_CD AS BRAND_CD,
MA_FORMULA_CD AS MA_FORMULA_CD,
FISCAL_MO AS FISCAL_MO,
SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
FROM_LOCATION_ID AS FROM_LOCATION_ID,
SOURCE_VENDOR_ID AS SOURCE_VENDOR_ID,
COMPANY_ID AS COMPANY_ID,
MA_EVENT_DESC AS MA_EVENT_DESC,
EM_VENDOR_FUNDING_ID AS EM_VENDOR_FUNDING_ID,
EM_COMMENT AS EM_COMMENT,
EM_BILL_ALT_VENDOR_FLAG AS EM_BILL_ALT_VENDOR_FLAG,
EM_ALT_VENDOR_ID AS EM_ALT_VENDOR_ID,
EM_ALT_VENDOR_NAME AS EM_ALT_VENDOR_NAME,
EM_ALT_VENDOR_COUNTRY_CD AS EM_ALT_VENDOR_COUNTRY_CD,
EM_VENDOR_ID AS EM_VENDOR_ID,
EM_VENDOR_NAME AS EM_VENDOR_NAME,
EM_VENDOR_COUNTRY_CD AS EM_VENDOR_COUNTRY_CD,
VENDOR_NAME_TXT AS VENDOR_NAME_TXT,
MA_PCT_IND AS MA_PCT_IND,
NEW_MA_AMT AS MA_AMT,
MA_MAX_AMT AS MA_MAX_AMT,
UPDATE_DT AS UPDATE_DT,
LOAD_DT AS LOAD_DT FROM UPD_InsertDeleteOrUpdate_9""")

# COMMAND ----------
# DBTITLE 1, MA_EVENT_RESTATE_HIST


spark.sql("""INSERT INTO MA_EVENT_RESTATE_HIST SELECT LOAD_DT AS LOAD_DT,
MA_EVENT_ID AS MA_EVENT_ID,
OFFER_ID AS OFFER_ID,
SAP_DEPT_ID AS SAP_DEPT_ID,
PRODUCT_ID AS PRODUCT_ID,
COUNTRY_CD AS COUNTRY_CD,
START_DT AS START_DT,
END_DT AS END_DT,
MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
LOCATION_ID AS LOCATION_ID,
MOVEMENT_ID AS MOVEMENT_ID,
VALUATION_CLASS_CD AS VALUATION_CLASS_CD,
GL_ACCT_NBR AS GL_ACCT_NBR,
LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
ROYALTY_BRAND_ID AS ROYALTY_BRAND_ID,
BRAND_CD AS BRAND_CD,
MA_FORMULA_CD AS MA_FORMULA_CD,
FISCAL_MO AS FISCAL_MO,
SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
FROM_LOCATION_ID AS FROM_LOCATION_ID,
SOURCE_VENDOR_ID AS SOURCE_VENDOR_ID,
COMPANY_ID AS COMPANY_ID,
MA_EVENT_DESC AS MA_EVENT_DESC,
EM_VENDOR_FUNDING_ID AS EM_VENDOR_FUNDING_ID,
EM_COMMENT AS EM_COMMENT,
EM_BILL_ALT_VENDOR_FLAG AS EM_BILL_ALT_VENDOR_FLAG,
EM_ALT_VENDOR_ID AS EM_ALT_VENDOR_ID,
EM_ALT_VENDOR_NAME AS EM_ALT_VENDOR_NAME,
EM_ALT_VENDOR_COUNTRY_CD AS EM_ALT_VENDOR_COUNTRY_CD,
EM_VENDOR_ID AS EM_VENDOR_ID,
EM_VENDOR_NAME AS EM_VENDOR_NAME,
EM_VENDOR_COUNTRY_CD AS EM_VENDOR_COUNTRY_CD,
VENDOR_NAME_TXT AS VENDOR_NAME_TXT,
MA_PCT_IND AS MA_PCT_IND,
ORIG_MA_AMT AS MA_AMT,
MA_MAX_AMT AS MA_MAX_AMT,
INS_UPD_DEL_FLAG AS INS_UPD_DEL_FLAG FROM UPD_InsertOnly_12""")